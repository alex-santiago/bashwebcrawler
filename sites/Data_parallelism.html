<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Data parallelism - Wikipedia</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"Data_parallelism","wgTitle":"Data parallelism","wgCurRevisionId":786761712,"wgRevisionId":786761712,"wgArticleId":9467420,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Articles with example pseudocode","Parallel computing"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Data_parallelism","wgRelevantArticleId":9467420,"wgRequestId":"WdPkXgpAEKkAAFKba-8AAAAN","wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgFlaggedRevsParams":{"tags":{}},"wgStableRevisionId":null,"wgWikiEditorEnabledModules":{"toolbar":true,"preview":false,"publish":false},"wgBetaFeaturesFeatures":[],"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":false,"wgPopupsShouldSendModuleToUser":false,"wgPopupsConflictsWithNavPopupGadget":false,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en","usePageImages":true,"usePageDescriptions":true},"wgPreferredVariant":"en","wgMFExpandAllSectionsUserOption":false,"wgMFDisplayWikibaseDescriptions":{"search":true,"nearby":true,"watchlist":true,"tagline":false},"wgRelatedArticles":null,"wgRelatedArticlesUseCirrusSearch":true,"wgRelatedArticlesOnlyUseCirrusSearch":false,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralNoticeCookiesToDelete":[],"wgCentralNoticeCategoriesUsingLegacy":["Fundraising","fundraising"],"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgWikibaseItemId":"Q3124522","wgCentralAuthMobileDomain":false,"wgVisualEditorToolbarScrollOffset":0,"wgVisualEditorUnsupportedEditParams":["undo","undoafter","veswitched"],"wgEditSubmitButtonLabelPublish":false});mw.loader.state({"ext.gadget.charinsert-styles":"ready","ext.globalCssJs.user.styles":"ready","ext.globalCssJs.site.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","ext.pygments":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready","ext.globalCssJs.user":"ready","ext.globalCssJs.site":"ready"});mw.loader.implement("user.tokens@1dqfd7l",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/

});mw.loader.load(["ext.cite.a11y","ext.math.scripts","site","mediawiki.page.startup","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging.subscriber","ext.wikimediaEvents","ext.navigationTiming","ext.uls.eventlogger","ext.uls.init","ext.uls.interface","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"]);});</script>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.pygments%2CwikimediaBadges%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.sectionAnchor%7Cmediawiki.skinning.interface%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.gadget.charinsert-styles&amp;only=styles&amp;skin=vector"/>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.31.0-wmf.1"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/a/a7/Sequential_vs._Data_Parallel_job_execution.png"/>
<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Data_parallelism"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Data_parallelism&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Data_parallelism&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Data_parallelism"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/resources/lib/html5shiv/html5shiv.min.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-Data_parallelism rootpage-Data_parallelism vector-nav-directionality skin-vector action-view">		<div id="mw-page-base" class="noprint"></div>
		<div id="mw-head-base" class="noprint"></div>
		<div id="content" class="mw-body" role="main">
			<a id="top"></a>

							<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
						<div class="mw-indicators mw-body-content">
</div>
			<h1 id="firstHeading" class="firstHeading" lang="en">Data parallelism</h1>
									<div id="bodyContent" class="mw-body-content">
									<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
								<div id="contentSub"></div>
												<div id="jump-to-nav" class="mw-jump">
					Jump to:					<a href="#mw-head">navigation</a>, 					<a href="#p-search">search</a>
				</div>
				<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div class="thumb tright">
<div class="thumbinner" style="width:399px;"><a href="/wiki/File:Sequential_vs._Data_Parallel_job_execution.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Sequential_vs._Data_Parallel_job_execution.png/397px-Sequential_vs._Data_Parallel_job_execution.png" width="397" height="263" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Sequential_vs._Data_Parallel_job_execution.png/596px-Sequential_vs._Data_Parallel_job_execution.png 1.5x, //upload.wikimedia.org/wikipedia/commons/a/a7/Sequential_vs._Data_Parallel_job_execution.png 2x" data-file-width="612" data-file-height="406" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Sequential_vs._Data_Parallel_job_execution.png" class="internal" title="Enlarge"></a></div>
Sequential vs. Data Parallel job execution</div>
</div>
</div>
<p><b>Data parallelism</b> is a form of parallelization across multiple <a href="/wiki/Central_processing_unit" title="Central processing unit">processors</a> in <a href="/wiki/Parallel_computing" title="Parallel computing">parallel computing</a> environments. It focuses on distributing the data across different nodes, which operate on the data in parallel. It can be applied on regular data structures like arrays and matrices by working on each element in parallel. It contrasts to <a href="/wiki/Task_parallelism" title="Task parallelism">task parallelism</a> as another form of parallelism.</p>
<p>A data parallel job on an array of 'n' elements can be divided equally among all the processors. Let us assume we want to sum all the elements of the given array and the time for a single addition operation is Ta time units. In the case of sequential execution, the time taken by the process will be n*Ta time units as it sums up all the elements of an array. On the other hand, if we execute this job as a data parallel job on 4 processors the time taken would reduce to (n/4)*Ta + Merging overhead time units. Parallel execution results in a speedup of 4 over sequential execution. One important thing to note is that the <a href="/wiki/Locality_of_reference" title="Locality of reference">locality of data references</a> plays an important part in evaluating the performance of a data parallel programming model. Locality of data depends on the memory accesses performed by the program as well as the size of the cache.</p>
<p></p>
<div id="toc" class="toc">
<div class="toctitle">
<h2>Contents</h2>
</div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Description"><span class="tocnumber">2</span> <span class="toctext">Description</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Example"><span class="tocnumber">3</span> <span class="toctext">Example</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Steps_to_parallelization"><span class="tocnumber">4</span> <span class="toctext">Steps to parallelization</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Data_parallelism_vs._task_parallelism"><span class="tocnumber">5</span> <span class="toctext">Data parallelism vs. task parallelism</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Data_Parallelism_vs._Model_Parallelism.5B4.5D"><span class="tocnumber">6</span> <span class="toctext">Data Parallelism vs. Model Parallelism<sup>[4]</sup></span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#Mixed_data_and_task_parallelism.5B5.5D"><span class="tocnumber">7</span> <span class="toctext">Mixed data and task parallelism<sup>[5]</sup></span></a></li>
<li class="toclevel-1 tocsection-8"><a href="#Data_parallel_programming_environments"><span class="tocnumber">8</span> <span class="toctext">Data parallel programming environments</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#Applications"><span class="tocnumber">9</span> <span class="toctext">Applications</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#See_also"><span class="tocnumber">10</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#Notes"><span class="tocnumber">11</span> <span class="toctext">Notes</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#References"><span class="tocnumber">12</span> <span class="toctext">References</span></a></li>
</ul>
</div>
<p></p>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Exploitation of the concept of Data Parallelism started in 1960s with the development of Solomon machine. Solomon machine, also called a <a href="/wiki/Vector_processor" title="Vector processor">vector processor</a> wanted to expedite the math performance by working on a large data array(operating on multiple data in consecutive time steps). <a href="/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">Concurrency</a> of data was also exploited by operating on multiple data points at the same time using a single instruction. These generation of processors were called Array Processors.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">[1]</a></sup> Today, data parallelism is best exemplified in <a href="/wiki/Graphics_processing_unit" title="Graphics processing unit">graphics processing units</a>(GPUs) which use both the techniques of operating on multiple data points in space and time using a single instruction.</p>
<h2><span class="mw-headline" id="Description">Description</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=2" title="Edit section: Description">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In a multiprocessor system executing a single set of instructions (<a href="/wiki/SIMD" title="SIMD">SIMD</a>), data parallelism is achieved when each processor performs the same task on different pieces of distributed data. In some situations, a single execution thread controls operations on all pieces of data. In others, different threads control the operation, but they execute the same code.</p>
<p>For instance, consider matrix multiplication and addition in a sequential manner as discussed in the example.</p>
<h2><span class="mw-headline" id="Example">Example</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=3" title="Edit section: Example">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Below is the sequential pseudo-code for multiplication and addition of two matrices where the result is stored in the matrix C. The pseudo-code for multiplication calculates the dot product of two matrices A, B and stores the result into the output matrix C.</p>
<p>If the following programs were executed sequentially, the time taken to calculate the result would be of the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" >
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>O</mi>
        <mo stretchy="false">(</mo>
        <msup>
          <mi>n</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>3</mn>
          </mrow>
        </msup>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle O(n^{3})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6b04f5c5cfea38f43406d9442387ad28555e2609" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:6.081ex; height:3.176ex;" alt="O(n^{3})" /></span>(assuming row lengths and column lengths of both matrices are n) and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" >
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>O</mi>
        <mo stretchy="false">(</mo>
        <mi>n</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle O(n)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34109fe397fdcff370079185bfdb65826cb5565a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.019ex; height:2.843ex;" alt="O(n)" /></span>for multiplication and addition respectively.</p>
<div class="mw-highlight mw-content-ltr" dir="ltr">
<pre>
<span class="c1">//Matrix Multiplication</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">row_length_A</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="p">{</span>		
        <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">column_length_B</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">)</span>
        <span class="p">{</span>
                <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span><span class="o">&lt;</span><span class="n">column_length_A</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span>
                <span class="p">{</span>
                        <span class="n">sum</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">B</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">];</span>
                <span class="p">}</span>
                <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">sum</span><span class="p">;</span>
        <span class="p">}</span>
<span class="p">}</span>
</pre></div>
<div class="mw-highlight mw-content-ltr" dir="ltr">
<pre>
<span class="c1">//Array addition</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span><span class="n">i</span><span class="o">&lt;</span><span class="n">n</span><span class="p">;</span><span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">=</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">b</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
    <span class="p">}</span>
</pre></div>
<p>We can exploit data parallelism in the preceding codes to execute it faster as the arithmetic is loop independent. Parallelization of the matrix multiplication code is achieved by using <a href="/wiki/OpenMP" title="OpenMP">OpenMP</a>. An OpenMP directive, "omp parallel for" instructs the compiler to execute the code in the for loop in parallel. For multiplication, we can divide matrix A and B into blocks along rows and columns respectively. This allows us to calculate every element in matrix C individually thereby making the task parallel. For example: <i>A[m x n] dot B [n x k]</i> can be finished in <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" >
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>O</mi>
        <mo stretchy="false">(</mo>
        <mi>n</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle O(n)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34109fe397fdcff370079185bfdb65826cb5565a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.019ex; height:2.843ex;" alt="O(n)" /></span> instead of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML" >
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>O</mi>
        <mo stretchy="false">(</mo>
        <mi>m</mi>
        <mo>&#x2217;<!-- ∗ --></mo>
        <mi>n</mi>
        <mo>&#x2217;<!-- ∗ --></mo>
        <mi>k</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle O(m*n*k)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/49324edc2a64f04db3fdf3d6947b8c97db2aac7a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.702ex; height:2.843ex;" alt="{\displaystyle O(m*n*k)}" /></span> when executed in parallel using <i>m*k</i> processors.</p>
<div class="center">
<div class="thumb tnone">
<div class="thumbinner" style="width:752px;"><a href="/wiki/File:Data_Parallelism_in_matrix_multiplication.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/6/68/Data_Parallelism_in_matrix_multiplication.png" width="750" height="287" class="thumbimage" data-file-width="750" data-file-height="287" /></a>
<div class="thumbcaption">
<div class="magnify"><a href="/wiki/File:Data_Parallelism_in_matrix_multiplication.png" class="internal" title="Enlarge"></a></div>
Data Parallelism in matrix multiplication</div>
</div>
</div>
</div>
<div class="mw-highlight mw-content-ltr" dir="ltr">
<pre>
<span class="c1">//Matrix multiplication in parallel</span>
<span class="cp">#pragma omp parallel for schedule(dynamic,1) collapse(2)</span>
<span class="k">for</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">i</span><span class="o">&lt;</span><span class="n">row_length_A</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">k</span><span class="o">&lt;</span><span class="n">column_length_B</span><span class="p">;</span> <span class="n">k</span><span class="o">++</span><span class="p">){</span>
                <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
                <span class="k">for</span> <span class="p">(</span><span class="n">j</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="n">j</span><span class="o">&lt;</span><span class="n">column_length_A</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">){</span>
                        <span class="n">sum</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">*</span><span class="n">B</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="n">k</span><span class="p">];</span>
                <span class="p">}</span>
                <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span><span class="o">=</span><span class="n">sum</span><span class="p">;</span>
        <span class="p">}</span>
<span class="p">}</span>
</pre></div>
<p>It can be observed from the example that a lot of processors will be required as the matrix sizes keep on increasing. Keeping the execution time low is the priority but as the matrix size increases, we are faced with other constraints like complexity of such a system and its associated costs. Therefore, constraining the number of processors in the system, we can still apply the same principle and divide the data into bigger chunks to calculate the product of two matrices.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">[2]</a></sup></p>
<p>For addition of arrays in a data parallel implementation, let’s assume a more modest system with two <a href="/wiki/Central_processing_unit" title="Central processing unit">Central Processing Units</a> (CPU) A and B, CPU A could add all elements from the top half of the arrays, while CPU B could add all elements from the bottom half of the arrays. Since the two processors work in parallel, the job of performing array addition would take one half the time of performing the same operation in serial using one CPU alone.</p>
<p>The program expressed in <a href="/wiki/Pseudocode" title="Pseudocode">pseudocode</a> below—which applies some arbitrary operation, <code>foo</code>, on every element in the array <code>d</code>—illustrates data parallelism:<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">[nb 1]</a></sup></p>
<pre>
if CPU = "a"
    lower_limit := 1
    upper_limit := round(d.length/2)
else if CPU = "b"
    lower_limit := round(d.length/2) + 1
    upper_limit := d.length

for i from lower_limit to upper_limit by 1
    foo(d[i])
</pre>
<p>In an <a href="/wiki/SPMD" title="SPMD">SPMD</a> system executed on 2 processor system, both CPUs will execute the code.</p>
<p>Data parallelism emphasizes the distributed (parallel) nature of the data, as opposed to the processing (task parallelism). Most real programs fall somewhere on a continuum between task parallelism and data parallelism.</p>
<h2><span class="mw-headline" id="Steps_to_parallelization">Steps to parallelization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=4" title="Edit section: Steps to parallelization">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The process of parallelizing a sequential program can be broken down into four discrete steps.<sup id="cite_ref-Solihin_4-0" class="reference"><a href="#cite_note-Solihin-4">[3]</a></sup></p>
<table class="wikitable">
<tr>
<th>Type</th>
<th>Description</th>
</tr>
<tr>
<td>Decomposition</td>
<td>The program is broken down into tasks, the smallest exploitable unit of concurrence.</td>
</tr>
<tr>
<td>Assignment</td>
<td>Tasks are assigned to processes.</td>
</tr>
<tr>
<td>Orchestration</td>
<td>Data access, communication, and synchronization of processes.</td>
</tr>
<tr>
<td>Mapping</td>
<td>Processes are bound to processors.</td>
</tr>
</table>
<h2><span class="mw-headline" id="Data_parallelism_vs._task_parallelism">Data parallelism vs. task parallelism</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=5" title="Edit section: Data parallelism vs. task parallelism">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="wikitable">
<tr>
<th>Data Parallelism</th>
<th>Task Parallelism</th>
</tr>
<tr>
<td>Same operations are performed on different subsets of same data.</td>
<td>Different operations are performed on the same or different data.</td>
</tr>
<tr>
<td>Synchronous computation</td>
<td>Asynchronous computation</td>
</tr>
<tr>
<td>Speedup is more as there is only one execution thread operating on all sets of data.</td>
<td>Speedup is less as each processor will execute a different thread or process on the same or different set of data.</td>
</tr>
<tr>
<td>Amount of parallelization is proportional to the input data size.</td>
<td>Amount of parallelization is proportional to the number of independent tasks to be performed.</td>
</tr>
<tr>
<td>Designed for optimum <a href="/wiki/Load_balancing_(computing)" title="Load balancing (computing)">load balance</a> on multi processor system.</td>
<td>Load balancing depends on the availability of the hardware and scheduling algorithms like static and dynamic scheduling.</td>
</tr>
</table>
<h2><span id="Data_Parallelism_vs._Model_Parallelism[4]"></span><span class="mw-headline" id="Data_Parallelism_vs._Model_Parallelism.5B4.5D">Data Parallelism vs. Model Parallelism<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">[4]</a></sup></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=6" title="Edit section: Data Parallelism vs. Model Parallelism[4]">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="wikitable">
<tr>
<th>Data Parallelism</th>
<th>Model Parallelism</th>
</tr>
<tr>
<td>Same model is used for every thread but the data given to each of them is divided and shared.</td>
<td>Same data is used for every thread, and model is split among threads.</td>
</tr>
<tr>
<td>It is fast for small networks but very slow for large networks since large amounts of data needs to be transferred between processors all at once.</td>
<td>It is slow for small networks and fast for large networks.</td>
</tr>
<tr>
<td>Data parallelism is ideally used in array and matrix computations and convolutional neural networks</td>
<td>Model parallelism finds its applications in deep learning</td>
</tr>
</table>
<h2><span id="Mixed_data_and_task_parallelism[5]"></span><span class="mw-headline" id="Mixed_data_and_task_parallelism.5B5.5D">Mixed data and task parallelism<sup id="cite_ref-6" class="reference"><a href="#cite_note-6">[5]</a></sup></span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=7" title="Edit section: Mixed data and task parallelism[5]">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Data and task parallelism, can be simultaneously implemented by combining them together for the same application. This is called Mixed data and task parallelism. Mixed parallelism requires sophisticated scheduling algorithms and software support. It is the best kind of parallelism when communication is slow and number of processors is large.</p>
<p>Mixed data and task parallelism has many applications. It is particularly used in the following applications:</p>
<ol>
<li>Mixed data and task parallelism finds applications in the global climate modeling. Large data parallel computations are performed by creating grids of data representing earth’s atmosphere and oceans and task parallelism is employed for simulating the function and model of the physical processes.</li>
<li>In timing based circuit simulation. The data is divided among different sub-circuits and parallelism is achieved with orchestration from the tasks.</li>
</ol>
<h2><span class="mw-headline" id="Data_parallel_programming_environments">Data parallel programming environments</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=8" title="Edit section: Data parallel programming environments">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>A variety of data parallel programming environments are available today, most widely used of which are:</p>
<ol>
<li><a href="/wiki/Message_Passing_Interface" title="Message Passing Interface">Message Passing Interface</a>: It is a cross-platform message passing programming interface for parallel computers. It defines the semantics of library functions to allow users to write portable message passing programs in C, C++ and Fortran.</li>
<li>Open Multi Processing<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">[6]</a></sup> (Open MP): It’s an Application Programming Interface (API) which supports shared memory programming models on multiple platforms of multiprocessor systems .</li>
<li><a href="/wiki/CUDA" title="CUDA">CUDA</a> and <a href="/wiki/OpenACC" title="OpenACC">OpenACC</a>: CUDA and OpenACC (respectively) are parallel computing API platforms designed to allow a software engineer to utilize GPU’s computational units for general purpose processing.</li>
<li><a href="/wiki/Threading_Building_Blocks" title="Threading Building Blocks">Threading Building Blocks</a> and <a href="/wiki/RaftLib" title="RaftLib">RaftLib</a>: Both open source programming environments that enable mixed data/task parallelism in C/C++ environments across heterogeneous resources.</li>
</ol>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=9" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Data Parallelism finds its applications in a variety of fields ranging from physics, chemistry, biology, material sciences to signal processing. Sciences imply data parallelism for simulating models like molecular dynamics,<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">[7]</a></sup> sequence analysis of genome data <sup id="cite_ref-9" class="reference"><a href="#cite_note-9">[8]</a></sup> and other physical phenomenon. Driving forces in signal processing for data parallelism are video encoding, image and graphics processing, wireless communications <sup id="cite_ref-10" class="reference"><a href="#cite_note-10">[9]</a></sup> to name a few.</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=10" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul>
<li><a href="/wiki/Active_message" title="Active message">Active message</a></li>
<li><a href="/wiki/Instruction_level_parallelism" class="mw-redirect" title="Instruction level parallelism">Instruction level parallelism</a></li>
<li><a href="/wiki/Scalable_parallelism" title="Scalable parallelism">Scalable parallelism</a></li>
<li><a href="/wiki/Thread_level_parallelism" class="mw-redirect" title="Thread level parallelism">Thread level parallelism</a></li>
<li><a href="/wiki/Parallel_programming_model" title="Parallel programming model">Parallel programming model</a></li>
</ul>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=11" title="Edit section: Notes">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="mw-references-wrap">
<ol class="references">
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">Some input data (e.g. when <code>d.length</code> evaluates to 1 and <code>round</code> rounds towards zero [this is just an example, there are no requirements on what type of rounding is used]) will lead to <code>lower_limit</code> being greater than <code>upper_limit</code>, it's assumed that the loop will exit immediately (i.e. zero iterations will occur) when this happens.</span></li>
</ol>
</div>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Data_parallelism&amp;action=edit&amp;section=12" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://www.ece.cmu.edu/~ece740/f13/lib/exe/fetch.php%3Fmedia%3Dseth-740-fall13-module5.1-simd-vector-gpu.pdf">"SIMD/Vector/GPU"</a> <span style="font-size:85%;">(PDF)</span><span class="reference-accessdate">. Retrieved <span class="nowrap">2016-09-07</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.btitle=SIMD%2FVector%2FGPU&amp;rft.genre=unknown&amp;rft_id=https%3A%2F%2Fwww.ece.cmu.edu%2F~ece740%2Ff13%2Flib%2Fexe%2Ffetch.php%253Fmedia%253Dseth-740-fall13-module5.1-simd-vector-gpu.pdf&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation web">Barney, Blaise. <a rel="nofollow" class="external text" href="https://computing.llnl.gov/tutorials/parallel_comp/">"Introduction to Parallel Computing"</a>. <i>computing.llnl.gov</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2016-09-07</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.atitle=Introduction+to+Parallel+Computing&amp;rft.aufirst=Blaise&amp;rft.aulast=Barney&amp;rft.genre=unknown&amp;rft.jtitle=computing.llnl.gov&amp;rft_id=https%3A%2F%2Fcomputing.llnl.gov%2Ftutorials%2Fparallel_comp%2F&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-Solihin-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-Solihin_4-0">^</a></b></span> <span class="reference-text"><cite class="citation book">Solihin, Yan (2016). <i>Fundamentals of Parallel Architecture</i>. Boca Raton, FL: CRC Press. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4822-1118-4" title="Special:BookSources/978-1-4822-1118-4">978-1-4822-1118-4</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.aufirst=Yan&amp;rft.aulast=Solihin&amp;rft.btitle=Fundamentals+of+Parallel+Architecture&amp;rft.date=2016&amp;rft.genre=book&amp;rft.isbn=978-1-4822-1118-4&amp;rft.place=Boca+Raton%2C+FL&amp;rft.pub=CRC+Press&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://timdettmers.com/2014/11/09/model-parallelism-deep-learning/">"How to Parallelize Deep Learning on GPUs Part 2/2: Model Parallelism"</a>. <i>Tim Dettmers</i>. 2014-11-09<span class="reference-accessdate">. Retrieved <span class="nowrap">2016-09-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.atitle=How+to+Parallelize+Deep+Learning+on+GPUs+Part+2%2F2%3A+Model+Parallelism&amp;rft.date=2014-11-09&amp;rft.genre=unknown&amp;rft.jtitle=Tim+Dettmers&amp;rft_id=http%3A%2F%2Ftimdettmers.com%2F2014%2F11%2F09%2Fmodel-parallelism-deep-learning%2F&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://www.netlib.org/lapack/lawnspdf/lawn97.pdf">"The Netlib"</a> <span style="font-size:85%;">(PDF)</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.btitle=The+Netlib&amp;rft.genre=unknown&amp;rft_id=http%3A%2F%2Fwww.netlib.org%2Flapack%2Flawnspdf%2Flawn97.pdf&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://openmp.org/wp/">"OpenMP.org"</a>. <i>openmp.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2016-09-07</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.atitle=OpenMP.org&amp;rft.genre=unknown&amp;rft.jtitle=openmp.org&amp;rft_id=http%3A%2F%2Fopenmp.org%2Fwp%2F&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><cite class="citation journal">Boyer, L. L; Pawley, G. S (1988-10-01). <a rel="nofollow" class="external text" href="http://www.sciencedirect.com/science/article/pii/0021999188900575">"Molecular dynamics of clusters of particles interacting with pairwise forces using a massively parallel computer"</a>. <i>Journal of Computational Physics</i>. <b>78</b> (2): 405–423. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1016%2F0021-9991%2888%2990057-5">10.1016/0021-9991(88)90057-5</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.atitle=Molecular+dynamics+of+clusters+of+particles+interacting+with+pairwise+forces+using+a+massively+parallel+computer&amp;rft.au=Pawley%2C+G.+S&amp;rft.aufirst=L.+L&amp;rft.aulast=Boyer&amp;rft.date=1988-10-01&amp;rft.genre=article&amp;rft.issue=2&amp;rft.jtitle=Journal+of+Computational+Physics&amp;rft.pages=405-423&amp;rft.volume=78&amp;rft_id=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2F0021999188900575&amp;rft_id=info%3Adoi%2F10.1016%2F0021-9991%2888%2990057-5&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="http://ieeexplore.ieee.org/document/674320/">"IEEE Xplore Document - Parallel computation in biological sequence analysis"</a>. <i>ieeexplore.ieee.org</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2016-09-07</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.atitle=IEEE+Xplore+Document+-+Parallel+computation+in+biological+sequence+analysis&amp;rft.genre=unknown&amp;rft.jtitle=ieeexplore.ieee.org&amp;rft_id=http%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F674320%2F&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation journal">Singh, H.; Lee, Ming-Hau; Lu, Guangming; Kurdahi, F.J.; Bagherzadeh, N.; Filho, E.M. Chaves (2000-06-01). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/3044209_MorphoSys_An_integrated_reconfigurable_system_for_data-parallel_and_computation-intensive_applications">"MorphoSys: an integrated reconfigurable system for data-parallel and computation-intensive applications"</a>. <i>IEEE Transactions on Computers</i>. <b>49</b> (5): 465–481. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0018-9340">0018-9340</a>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1109%2F12.859540">10.1109/12.859540</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AData+parallelism&amp;rft.atitle=MorphoSys%3A+an+integrated+reconfigurable+system+for+data-parallel+and+computation-intensive+applications&amp;rft.au=Bagherzadeh%2C+N.&amp;rft.au=Filho%2C+E.M.+Chaves&amp;rft.au=Kurdahi%2C+F.J.&amp;rft.au=Lee%2C+Ming-Hau&amp;rft.au=Lu%2C+Guangming&amp;rft.aufirst=H.&amp;rft.aulast=Singh&amp;rft.date=2000-06-01&amp;rft.genre=article&amp;rft.issn=0018-9340&amp;rft.issue=5&amp;rft.jtitle=IEEE+Transactions+on+Computers&amp;rft.pages=465-481&amp;rft.volume=49&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F3044209_MorphoSys_An_integrated_reconfigurable_system_for_data-parallel_and_computation-intensive_applications&amp;rft_id=info%3Adoi%2F10.1109%2F12.859540&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal" class="Z3988"><span style="display:none;">&#160;</span></span></span></li>
</ol>
</div>
</div>
<ul>
<li><a href="/wiki/Daniel_Hillis" class="mw-redirect" title="Daniel Hillis">Hillis, W. Daniel</a> and <a href="/wiki/Guy_Steele" class="mw-redirect" title="Guy Steele">Steele, Guy L.</a>, <a rel="nofollow" class="external text" href="http://dx.doi.org/10.1145/7902.7903"><cite>Data Parallel Algorithms</cite></a> <a href="/wiki/Communications_of_the_ACM" title="Communications of the ACM">Communications of the ACM</a> December 1986</li>
<li>Blelloch, Guy E, <cite>Vector Models for Data-Parallel Computing</cite> MIT Press 1990. <a href="/wiki/International_Standard_Book_Number_(identifier)" class="mw-redirect" title="International Standard Book Number (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-262-02313-X" title="Special:BookSources/0-262-02313-X">0-262-02313-X</a></li>
</ul>
<div role="navigation" class="navbox" aria-labelledby="Parallel_computing" style="padding:3px">
<table class="nowraplinks hlist collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit">
<tr>
<th scope="col" class="navbox-title" colspan="2">
<div class="plainlinks hlist navbar mini">
<ul>
<li class="nv-view"><a href="/wiki/Template:Parallel_computing" title="Template:Parallel computing"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none;">v</abbr></a></li>
<li class="nv-talk"><a href="/wiki/Template_talk:Parallel_computing" title="Template talk:Parallel computing"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none;">t</abbr></a></li>
<li class="nv-edit"><a class="external text" href="//en.wikipedia.org/w/index.php?title=Template:Parallel_computing&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none;">e</abbr></a></li>
</ul>
</div>
<div id="Parallel_computing" style="font-size:114%;margin:0 4em"><a href="/wiki/Parallel_computing" title="Parallel computing">Parallel computing</a></div>
</th>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%">General</th>
<td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Distributed_computing" title="Distributed computing">Distributed computing</a></li>
<li><a href="/wiki/Parallel_computing" title="Parallel computing">Parallel computing</a></li>
<li><a href="/wiki/Massively_parallel" title="Massively parallel">Massively parallel</a></li>
<li><a href="/wiki/Cloud_computing" title="Cloud computing">Cloud computing</a></li>
<li><a href="/wiki/Supercomputer" title="Supercomputer">High-performance computing</a></li>
<li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessing</a></li>
<li><a href="/wiki/Manycore_processor" title="Manycore processor">Manycore processor</a></li>
<li><a href="/wiki/General-purpose_computing_on_graphics_processing_units" title="General-purpose computing on graphics processing units">GPGPU</a></li>
<li><a href="/wiki/Computer_network" title="Computer network">Computer network</a></li>
<li><a href="/wiki/Systolic_array" title="Systolic array">Systolic array</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%">Levels</th>
<td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Bit-level_parallelism" title="Bit-level parallelism">Bit</a></li>
<li><a href="/wiki/Instruction-level_parallelism" title="Instruction-level parallelism">Instruction</a></li>
<li><a href="/wiki/Task_parallelism" title="Task parallelism">Thread</a></li>
<li><a href="/wiki/Task_parallelism" title="Task parallelism">Task</a></li>
<li><a class="mw-selflink selflink">Data</a></li>
<li><a href="/wiki/Memory-level_parallelism" title="Memory-level parallelism">Memory</a></li>
<li><a href="/wiki/Loop-level_parallelism" title="Loop-level parallelism">Loop</a></li>
<li><a href="/wiki/Pipeline_(computing)" title="Pipeline (computing)">Pipeline</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Multithreading_(computer_architecture)" title="Multithreading (computer architecture)">Multithreading</a></th>
<td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Temporal_multithreading" title="Temporal multithreading">Temporal</a></li>
<li><a href="/wiki/Simultaneous_multithreading" title="Simultaneous multithreading">Simultaneous</a> (SMT)</li>
<li><a href="/wiki/Speculative_multithreading" title="Speculative multithreading">Speculative</a> (SpMT)</li>
<li><a href="/wiki/Preemption_(computing)" title="Preemption (computing)">Preemptive</a></li>
<li><a href="/wiki/Computer_multitasking#Cooperative_multitasking" title="Computer multitasking">Cooperative</a></li>
<li><a href="/wiki/Bulldozer_(microarchitecture)#Bulldozer_core" title="Bulldozer (microarchitecture)">Clustered Multi-Thread</a> (CMT)</li>
<li><a href="/wiki/Hardware_scout" title="Hardware scout">Hardware scout</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%">Theory</th>
<td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Parallel_random-access_machine" title="Parallel random-access machine">PRAM model</a></li>
<li><a href="/wiki/Analysis_of_parallel_algorithms" title="Analysis of parallel algorithms">Analysis of parallel algorithms</a></li>
<li><a href="/wiki/Amdahl%27s_law" title="Amdahl's law">Amdahl's law</a></li>
<li><a href="/wiki/Gustafson%27s_law" title="Gustafson's law">Gustafson's law</a></li>
<li><a href="/wiki/Cost_efficiency" title="Cost efficiency">Cost efficiency</a></li>
<li><a href="/wiki/Karp%E2%80%93Flatt_metric" title="Karp–Flatt metric">Karp–Flatt metric</a></li>
<li><a href="/wiki/Parallel_slowdown" title="Parallel slowdown">Slowdown</a></li>
<li><a href="/wiki/Speedup" title="Speedup">Speedup</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%">Elements</th>
<td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Process_(computing)" title="Process (computing)">Process</a></li>
<li><a href="/wiki/Thread_(computing)" title="Thread (computing)">Thread</a></li>
<li><a href="/wiki/Fiber_(computer_science)" title="Fiber (computer science)">Fiber</a></li>
<li><a href="/wiki/Instruction_window" title="Instruction window">Instruction window</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%">Coordination</th>
<td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessing</a></li>
<li><a href="/wiki/Memory_coherence" title="Memory coherence">Memory coherency</a></li>
<li><a href="/wiki/Cache_coherence" title="Cache coherence">Cache coherency</a></li>
<li><a href="/wiki/Cache_invalidation" title="Cache invalidation">Cache invalidation</a></li>
<li><a href="/wiki/Barrier_(computer_science)" title="Barrier (computer science)">Barrier</a></li>
<li><a href="/wiki/Synchronization_(computer_science)" title="Synchronization (computer science)">Synchronization</a></li>
<li><a href="/wiki/Application_checkpointing" title="Application checkpointing">Application checkpointing</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Computer_programming" title="Computer programming">Programming</a></th>
<td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Stream_processing" title="Stream processing">Stream processing</a></li>
<li><a href="/wiki/Dataflow_programming" title="Dataflow programming">Dataflow programming</a></li>
<li><a href="/wiki/Parallel_programming_model" title="Parallel programming model">Models</a>
<ul>
<li><a href="/wiki/Implicit_parallelism" title="Implicit parallelism">Implicit parallelism</a></li>
<li><a href="/wiki/Explicit_parallelism" title="Explicit parallelism">Explicit parallelism</a></li>
<li><a href="/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">Concurrency</a></li>
</ul>
</li>
<li><a href="/wiki/Non-blocking_algorithm" title="Non-blocking algorithm">Non-blocking algorithm</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Computer_hardware" title="Computer hardware">Hardware</a></th>
<td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Flynn%27s_taxonomy" title="Flynn's taxonomy">Flynn's taxonomy</a>
<ul>
<li><a href="/wiki/SISD" title="SISD">SISD</a></li>
<li><a href="/wiki/SIMD" title="SIMD">SIMD</a></li>
<li><a href="/wiki/Single_instruction,_multiple_threads" title="Single instruction, multiple threads">SIMT</a></li>
<li><a href="/wiki/MISD" title="MISD">MISD</a></li>
<li><a href="/wiki/MIMD" title="MIMD">MIMD</a></li>
</ul>
</li>
<li><a href="/wiki/Dataflow_architecture" title="Dataflow architecture">Dataflow architecture</a></li>
<li><a href="/wiki/Instruction_pipelining" title="Instruction pipelining">Pipelined processor</a></li>
<li><a href="/wiki/Superscalar_processor" title="Superscalar processor">Superscalar processor</a></li>
<li><a href="/wiki/Vector_processor" title="Vector processor">Vector processor</a></li>
<li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessor</a>
<ul>
<li><a href="/wiki/Symmetric_multiprocessing" title="Symmetric multiprocessing">symmetric</a></li>
<li><a href="/wiki/Asymmetric_multiprocessing" title="Asymmetric multiprocessing">asymmetric</a></li>
</ul>
</li>
<li><a href="/wiki/Semiconductor_memory" title="Semiconductor memory">Memory</a>
<ul>
<li><a href="/wiki/Shared_memory" title="Shared memory">shared</a></li>
<li><a href="/wiki/Distributed_memory" title="Distributed memory">distributed</a></li>
<li><a href="/wiki/Distributed_shared_memory" title="Distributed shared memory">distributed shared</a></li>
<li><a href="/wiki/Uniform_memory_access" title="Uniform memory access">UMA</a></li>
<li><a href="/wiki/Non-uniform_memory_access" title="Non-uniform memory access">NUMA</a></li>
<li><a href="/wiki/Cache-only_memory_architecture" title="Cache-only memory architecture">COMA</a></li>
</ul>
</li>
<li><a href="/wiki/Massively_parallel" title="Massively parallel">Massively parallel computer</a></li>
<li><a href="/wiki/Computer_cluster" title="Computer cluster">Computer cluster</a></li>
<li><a href="/wiki/Grid_computing" title="Grid computing">Grid computer</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Application_programming_interface" title="Application programming interface">APIs</a></th>
<td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Ateji_PX" title="Ateji PX">Ateji PX</a></li>
<li><a href="/wiki/Boost_(C%2B%2B_libraries)#Multithreading_.E2.80.93_Boost.Thread" title="Boost (C++ libraries)">Boost.Thread</a></li>
<li><a href="/wiki/Charm%2B%2B" title="Charm++">Charm++</a></li>
<li><a href="/wiki/Cilk" title="Cilk">Cilk</a></li>
<li><a href="/wiki/Coarray_Fortran" title="Coarray Fortran">Coarray Fortran</a></li>
<li><a href="/wiki/CUDA" title="CUDA">CUDA</a></li>
<li><a href="/wiki/Dryad_(programming)" title="Dryad (programming)">Dryad</a></li>
<li><a href="/wiki/C%2B%2B_AMP" title="C++ AMP">C++ AMP</a></li>
<li><a href="/wiki/Global_Arrays" title="Global Arrays">Global Arrays</a></li>
<li><a href="/wiki/Message_Passing_Interface" title="Message Passing Interface">MPI</a></li>
<li><a href="/wiki/OpenMP" title="OpenMP">OpenMP</a></li>
<li><a href="/wiki/OpenCL" title="OpenCL">OpenCL</a></li>
<li><a href="/wiki/OpenHMPP" title="OpenHMPP">OpenHMPP</a></li>
<li><a href="/wiki/OpenACC" title="OpenACC">OpenACC</a></li>
<li><a href="/wiki/Parallel_Extensions#Task_Parallel_Library" title="Parallel Extensions">TPL</a></li>
<li><a href="/wiki/Parallel_Extensions#PLINQ" title="Parallel Extensions">PLINQ</a></li>
<li><a href="/wiki/Parallel_Virtual_Machine" title="Parallel Virtual Machine">PVM</a></li>
<li><a href="/wiki/POSIX_Threads" title="POSIX Threads">POSIX Threads</a></li>
<li><a href="/wiki/RaftLib" title="RaftLib">RaftLib</a></li>
<li><a href="/wiki/Unified_Parallel_C" title="Unified Parallel C">UPC</a></li>
<li><a href="/wiki/Threading_Building_Blocks" title="Threading Building Blocks">TBB</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<th scope="row" class="navbox-group" style="width:1%">Problems</th>
<td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px">
<div style="padding:0em 0.25em">
<ul>
<li><a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">Embarrassingly parallel</a></li>
<li><a href="/wiki/Software_lockout" title="Software lockout">Software lockout</a></li>
<li><a href="/wiki/Scalability" title="Scalability">Scalability</a></li>
<li><a href="/wiki/Race_condition#Computing" title="Race condition">Race condition</a></li>
<li><a href="/wiki/Deadlock" title="Deadlock">Deadlock</a></li>
<li><a href="/wiki/Deadlock#Livelock" title="Deadlock">Livelock</a></li>
<li><a href="/wiki/Starvation_(computer_science)" title="Starvation (computer science)">Starvation</a></li>
<li><a href="/wiki/Deterministic_algorithm" title="Deterministic algorithm">Deterministic algorithm</a></li>
<li><a href="/wiki/Parallel_slowdown" title="Parallel slowdown">Parallel slowdown</a></li>
</ul>
</div>
</td>
</tr>
<tr>
<td class="navbox-abovebelow" colspan="2">
<div>
<ul>
<li><img alt="Category" src="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" title="Category" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" data-file-width="36" data-file-height="31" />&#160;<a href="/wiki/Category:Parallel_computing" title="Category:Parallel computing">Category: parallel computing</a></li>
<li><img alt="Commons page" src="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" title="Commons page" width="12" height="16" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376" /> Media related to <a href="https://commons.wikimedia.org/wiki/Category:Parallel_computing" class="extiw" title="c:Category:Parallel computing">Parallel computing</a> at Wikimedia Commons</li>
</ul>
</div>
</td>
</tr>
</table>
</div>


<!-- 
NewPP limit report
Parsed by mw1261
Cached time: 20170920022908
Cache expiry: 1900800
Dynamic content: false
CPU time usage: 0.172 seconds
Real time usage: 0.497 seconds
Preprocessor visited node count: 848/1000000
Preprocessor generated node count: 0/1500000
Post‐expand include size: 37831/2097152 bytes
Template argument size: 544/2097152 bytes
Highest expansion depth: 15/40
Expensive parser function count: 0/500
Lua time usage: 0.058/10.000 seconds
Lua memory usage: 2.77 MB/50 MB
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  158.209      1 -total
 71.38%  112.924      1 Template:Reflist
 42.58%   67.371      6 Template:Cite_web
 15.39%   24.353      1 Template:ISBN
 13.14%   20.793      1 Template:Parallel_Computing
 11.36%   17.971      1 Template:Navbox
  7.04%   11.145      2 Template:Cite_journal
  6.69%   10.591      1 Template:Catalog_lookup_link
  4.37%    6.914      1 Template:Category-inline
  3.94%    6.230      2 Template:Icon
-->
</div>
<!-- Saved in parser cache with key enwiki:pcache:idhash:9467420-0!canonical!math=5 and timestamp 20170920022907 and revision id 786761712
 -->
<noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>					<div class="printfooter">
						Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Data_parallelism&amp;oldid=786761712">https://en.wikipedia.org/w/index.php?title=Data_parallelism&amp;oldid=786761712</a>"					</div>
				<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Parallel_computing" title="Category:Parallel computing">Parallel computing</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:Articles_with_example_pseudocode" title="Category:Articles with example pseudocode">Articles with example pseudocode</a></li></ul></div></div>				<div class="visualClear"></div>
							</div>
		</div>
		<div id="mw-navigation">
			<h2>Navigation menu</h2>

			<div id="mw-head">
									<div id="p-personal" role="navigation" class="" aria-labelledby="p-personal-label">
						<h3 id="p-personal-label">Personal tools</h3>
						<ul>
							<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Data+parallelism" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Data+parallelism" title="You're encouraged to log in; however, it's not mandatory. [o]" accesskey="o">Log in</a></li>						</ul>
					</div>
									<div id="left-navigation">
										<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">
						<h3 id="p-namespaces-label">Namespaces</h3>
						<ul>
														<li id="ca-nstab-main" class="selected"><span><a href="/wiki/Data_parallelism" title="View the content page [c]" accesskey="c">Article</a></span></li>
							<li id="ca-talk"><span><a href="/wiki/Talk:Data_parallelism" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></span></li>
						</ul>
					</div>
										<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">
												<h3 id="p-variants-label">
							<span>Variants</span>
						</h3>

						<div class="menu">
							<ul>
															</ul>
						</div>
					</div>
									</div>
				<div id="right-navigation">
										<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">
						<h3 id="p-views-label">Views</h3>
						<ul>
														<li id="ca-view" class="collapsible selected"><span><a href="/wiki/Data_parallelism">Read</a></span></li>
							<li id="ca-edit" class="collapsible"><span><a href="/w/index.php?title=Data_parallelism&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></span></li>
							<li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=Data_parallelism&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>
						</ul>
					</div>
										<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">
						<h3 id="p-cactions-label"><span>More</span></h3>

						<div class="menu">
							<ul>
															</ul>
						</div>
					</div>
										<div id="p-search" role="search">
						<h3>
							<label for="searchInput">Search</label>
						</h3>

						<form action="/w/index.php" id="searchform">
							<div id="simpleSearch">
							<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>							</div>
						</form>
					</div>
									</div>
			</div>
			<div id="mw-panel">
				<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page"  title="Visit the main page"></a></div>
						<div class="portal" role="navigation" id='p-navigation' aria-labelledby='p-navigation-label'>
			<h3 id='p-navigation-label'>Navigation</h3>

			<div class="body">
									<ul>
						<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content – the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id='p-interaction' aria-labelledby='p-interaction-label'>
			<h3 id='p-interaction-label'>Interaction</h3>

			<div class="body">
									<ul>
						<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id='p-tb' aria-labelledby='p-tb-label'>
			<h3 id='p-tb-label'>Tools</h3>

			<div class="body">
									<ul>
						<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Data_parallelism" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Data_parallelism" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Data_parallelism&amp;oldid=786761712" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Data_parallelism&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q3124522" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Data_parallelism&amp;id=786761712" title="Information on how to cite this page">Cite this page</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id='p-coll-print_export' aria-labelledby='p-coll-print_export-label'>
			<h3 id='p-coll-print_export-label'>Print/export</h3>

			<div class="body">
									<ul>
						<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Data+parallelism">Create a book</a></li><li id="coll-download-as-rdf2latex"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Data+parallelism&amp;action=show-selection-screen&amp;coll-download-url=%2Fw%2Findex.php%3Ftitle%3DSpecial%3ABook%26bookcmd%3Drender_article%26arttitle%3DData%2Bparallelism%26returnto%3DData%2Bparallelism%26oldid%3D786761712%26writer%3Drdf2latex">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Data_parallelism&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>					</ul>
							</div>
		</div>
			<div class="portal" role="navigation" id='p-lang' aria-labelledby='p-lang-label'>
			<h3 id='p-lang-label'>Languages</h3>

			<div class="body">
									<ul>
						<li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Paral%C2%B7lelisme_de_Dades" title="Paral·lelisme de Dades – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Paralelismo_de_datos" title="Paralelismo de datos – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Parall%C3%A9lisme_de_donn%C3%A9e" title="Parallélisme de donnée – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E3%83%87%E3%83%BC%E3%82%BF%E4%B8%A6%E5%88%97%E6%80%A7" title="データ並列性 – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-ro"><a href="https://ro.wikipedia.org/wiki/Memorie_paralel%C4%83" title="Memorie paralelă – Romanian" lang="ro" hreflang="ro" class="interlanguage-link-target">Română</a></li><li class="interlanguage-link interwiki-si"><a href="https://si.wikipedia.org/wiki/%E0%B6%AF%E0%B6%AD%E0%B7%8A%E0%B6%AD_%E0%B7%83%E0%B6%B8%E0%B7%8F%E0%B6%B1%E0%B7%8A%E0%B6%AD%E0%B6%BB%E0%B6%AD%E0%B7%8F%E0%B7%80" title="දත්ත සමාන්තරතාව – Sinhala" lang="si" hreflang="si" class="interlanguage-link-target">සිංහල</a></li><li class="interlanguage-link interwiki-simple"><a href="https://simple.wikipedia.org/wiki/Data_parallelism" title="Data parallelism – Simple English" lang="simple" hreflang="simple" class="interlanguage-link-target">Simple English</a></li><li class="interlanguage-link interwiki-sr"><a href="https://sr.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%B5%D0%BB%D0%B8%D0%B7%D0%B0%D0%BC_%D0%BF%D0%BE%D0%B4%D0%B0%D1%82%D0%B0%D0%BA%D0%B0" title="Паралелизам података – Serbian" lang="sr" hreflang="sr" class="interlanguage-link-target">Српски / srpski</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%9F%D0%B0%D1%80%D0%B0%D0%BB%D0%B5%D0%BB%D1%96%D0%B7%D0%BC_%D0%B4%D0%B0%D0%BD%D0%B8%D1%85" title="Паралелізм даних – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E8%B3%87%E6%96%99%E5%B9%B3%E8%A1%8C" title="資料平行 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li>					</ul>
				<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q3124522#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>			</div>
		</div>
				</div>
		</div>
		<div id="footer" role="contentinfo">
							<ul id="footer-info">
											<li id="footer-info-lastmod"> This page was last edited on 21 June 2017, at 13:22.</li>
											<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//wikimediafoundation.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//wikimediafoundation.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
									</ul>
							<ul id="footer-places">
											<li id="footer-places-privacy"><a href="https://wikimediafoundation.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
											<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
											<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
											<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
											<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
											<li id="footer-places-cookiestatement"><a href="https://wikimediafoundation.org/wiki/Cookie_statement">Cookie statement</a></li>
											<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Data_parallelism&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
									</ul>
										<ul id="footer-icons" class="noprint">
											<li id="footer-copyrightico">
							<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>						</li>
											<li id="footer-poweredbyico">
							<a href="//www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>						</li>
									</ul>
						<div style="clear:both"></div>
		</div>
		<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.172","walltime":"0.497","ppvisitednodes":{"value":848,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":37831,"limit":2097152},"templateargumentsize":{"value":544,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":0,"limit":500},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  158.209      1 -total"," 71.38%  112.924      1 Template:Reflist"," 42.58%   67.371      6 Template:Cite_web"," 15.39%   24.353      1 Template:ISBN"," 13.14%   20.793      1 Template:Parallel_Computing"," 11.36%   17.971      1 Template:Navbox","  7.04%   11.145      2 Template:Cite_journal","  6.69%   10.591      1 Template:Catalog_lookup_link","  4.37%    6.914      1 Template:Category-inline","  3.94%    6.230      2 Template:Icon"]},"scribunto":{"limitreport-timeusage":{"value":"0.058","limit":"10.000"},"limitreport-memusage":{"value":2902599,"limit":52428800}},"cachereport":{"origin":"mw1261","timestamp":"20170920022908","ttl":1900800,"transientcontent":false}}});});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":84,"wgHostname":"mw1214"});});</script>
	</body>
</html>
